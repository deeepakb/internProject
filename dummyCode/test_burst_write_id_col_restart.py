# Copyright 2021 Amazon.com, Inc. or its affiliates
# All Rights Reserved
import pytest
import logging
import uuid

from test_burst_write_id_col_commit import BurstWriteIdentityColumnBase
from raff.common.db.redshift_db import RedshiftDb
from raff.burst.burst_test import setup_teardown_burst
from raff.burst.burst_super_simulated_mode_helper import super_simulated_mode,\
    prepare_burst, get_burst_conn_params, cold_start
from raff.common.db.session import DbSession
from raff.common.dimensions import Dimensions
from raff.common.host_type import HostType
from raff.common.simulated_helper import create_localhost_snapshot

log = logging.getLogger(__name__)
__all__ = [super_simulated_mode, setup_teardown_burst]

DROP_TABLE = "DROP TABLE IF EXISTS burst_tbl_{};"
CREATE_TABLE = ("create table public.burst_tbl_{} "
                "(c0 int, c1 bigint identity(0, 1),"
                "c2 BIGINT GENERATED BY DEFAULT AS IDENTITY NOT NULL) {} {};")
INSERT_CMD = "INSERT INTO burst_tbl_{}(c0) values (1), (3), (5), (7), (9)"
INSERT_CMD_2 = ("INSERT INTO burst_tbl_{}(c0, c2) values "
                "(1,-10), (3,-10), (5,-10), (7,-10), (9,-10)")
UPDATE_CMD = "UPDATE burst_tbl_{} SET c0 = c0 - 1;"
GRANT_CMD = "GRANT ALL ON burst_tbl_{} TO PUBLIC;"
INSERT_SELECT_CMD = ("insert into burst_tbl_{}(c0) "
                     "select c0 from burst_tbl_{};")
DELETE_CMD = "DELETE FROM burst_tbl_{} where c0 < 100;"
BURST_GUCS = {
    'slices_per_node': '4',
    'burst_enable_write': 'true',
    'burst_enable_write_id_col': 'true'
}


@pytest.mark.super_simulated_no_stable_rc
@pytest.mark.encrypted_only
@pytest.mark.serial_only
@pytest.mark.localhost_only
@pytest.mark.skip_load_data
@pytest.mark.super_simulated_mode
@pytest.mark.custom_burst_gucs(gucs=BURST_GUCS)
@pytest.mark.custom_local_gucs(gucs={'burst_enable_write_id_col': 'true'})
@pytest.mark.usefixtures("super_simulated_mode")
@pytest.mark.session_ctx(user_type='bootstrap')
@pytest.mark.super_simulated_precommit
class BurstWriteIDColRestartBase(BurstWriteIdentityColumnBase):
    def _run_query(self, cluster, cursor, dml, num=1, burst=True):
        if burst:
            cursor.execute("set query_group to burst;")
        else:
            cursor.execute("set query_group to metrics;")
        for i in range(num):
            cursor.execute(dml)
            if burst:
                self._check_last_query_bursted(cluster, cursor)
            else:
                self._check_last_query_didnt_burst(cluster, cursor)

    def insert_select(self, cluster, cursor, tbl, num=1, burst=True):
        if burst:
            cursor.execute("set query_group to burst;")
        else:
            cursor.execute("set query_group to metrics;")
        for i in range(num):
            cursor.execute(INSERT_SELECT_CMD.format(tbl, tbl))
            if burst:
                self._check_last_query_bursted(cluster, cursor)
            else:
                self._check_last_query_didnt_burst(cluster, cursor)

    def _insert_tables(self, cluster, cursor):
        # Insert when set not bursted.
        cursor.execute("set query_group to metrics;")
        cursor.execute(INSERT_CMD.format("not_burst"))
        cursor.execute(INSERT_CMD_2.format("not_burst"))
        self._check_last_query_didnt_burst(cluster, cursor)
        # Insert when set bursted.
        cursor.execute("set query_group to burst;")
        cursor.execute(INSERT_CMD.format("burst"))
        cursor.execute(INSERT_CMD_2.format("burst"))
        self._check_last_query_bursted(cluster, cursor)

    def setup_tables(self, cursor, diststyle, sortkey):
        cursor.execute("set query_group to metrics;")
        cursor.execute(DROP_TABLE.format("burst"))
        cursor.execute(CREATE_TABLE.format("burst", diststyle, sortkey))
        cursor.execute(GRANT_CMD.format("burst"))
        cursor.execute(DROP_TABLE.format("not_burst"))
        cursor.execute(CREATE_TABLE.format("not_burst", diststyle, sortkey))
        cursor.execute(GRANT_CMD.format("not_burst"))

    def setup_data(self, cluster, cursor, tbl_diststyle):
        self._insert_tables(cluster, cursor)
        self.insert_select(cluster, cursor, "burst", 3, True)
        self.insert_select(cluster, cursor, "not_burst", 3, False)
        self._validate_table_data(cluster, cursor, tbl_diststyle)

    def _validate_table_data(self, cluster, cursor, tbl_diststyle):
        # If the table diststyle is not distkey, the inserted slice would not
        # be the same on main and burst clusters. So the inserted id col values
        # would not be the same on both clusters and cannot be validated.
        if "distkey" not in tbl_diststyle:
            return
        base_tbl_name = "burst_tbl_"
        self._start_and_wait_for_refresh(cluster)
        self._validate_content_equivalence(
            cluster,
            cursor,
            base_tbl_name + "burst",
            base_tbl_name + "not_burst",
        )

    def _validate_identity_column_data(self, cluster, cursor, tbl):
        self._start_and_wait_for_refresh(cluster)
        self._check_duplicated_id_col_values(cursor, tbl, "c1", "(-10)", True)
        self._check_duplicated_id_col_values(cursor, tbl, "c2", "(-10)", True)

    def _generate_crash_dml(self, tbl, vector):
        if vector.crash_dml == 'insert':
            return INSERT_CMD.format(tbl)
        elif vector.crash_dml == 'insert_select':
            return INSERT_SELECT_CMD.format(tbl, tbl)
        elif vector.crash_dml == 'update':
            return UPDATE_CMD.format(tbl)
        elif vector.crash_dml == 'delete':
            return DELETE_CMD.format(tbl)

    def base_bw_id_col_restart(self, db_session, vector, cluster, bg_commit):
        """
        The test crash PADB at burst write commit and validate table content
        after restart. The test does the following:
        1. Setup two tables: one for burst write, the other only run DMLs on
           main cluster.
        2. Run same DMLs on the tables.
        3. When running the last burst write, crash PADB manually and restart
           at different crash position.
        4. Compare two tables content and confirm they are the same.
        """
        fixed_slice_set = "xpx 'event set EtSimulateStartFromFixedSlice'"
        fixed_slice_unset = "xpx 'event unset EtSimulateStartFromFixedSlice'"
        if cluster.host_type != HostType.CLUSTER:
            burst_db = RedshiftDb(conn_params=get_burst_conn_params())
            with burst_db.cursor() as burst_cursor:
                burst_cursor.execute(fixed_slice_set)
        db_session_master = DbSession(cluster.get_conn_params(user='master'))
        with db_session_master.cursor() as cursor, \
                db_session.cursor() as cursor_bs:
            self.setup_tables(cursor_bs, vector.diststyle, vector.sortkey)
            self._start_and_wait_for_refresh(cluster)
            if cluster.host_type != HostType.CLUSTER:
                cursor_bs.execute(fixed_slice_set)
            self.setup_data(cluster, cursor, vector.diststyle)
            crash_dml_burst = self._generate_crash_dml("burst", vector)
            crash_dml_unburst = self._generate_crash_dml("not_burst", vector)
            self._run_query(cluster, cursor, crash_dml_unburst, 2, False)
            # To make sure content are the same in 2 tables at last. The insert
            # here should have different times based on crash pos.
            # 1. Insert 2 rows in non-burst table on main cluster.
            # 2. For EtCrashCommitBeforeP1, insert 2 rows on burst-table.
            #    3-rd insert below will crash before its persisted.
            # 3. For EtCrashCommitAfterP1, insert 1 row on burst-table.
            #    2-nd insert below will crash after its persisted.
            # 4. Restart cluster and check both tables - burst
            #    and non-burst - have same content.
            if vector.crash_pos == "EtCrashCommitBeforeP1":
                # For EtCrashCommitBeforeP1, PADB is crashed after data is not
                # persisted. Insert 2 times before restart on insert.
                self._run_query(cluster, cursor, crash_dml_burst, 2, True)
            else:
                # For EtCrashCommitAfterP1, PADB is crashed after data is
                # persisted. Insert 1 time before restart on insert.
                self._run_query(cluster, cursor, crash_dml_burst, 1, True)

            # Trigger crash and restart when burst write
            try:
                cluster.set_event(vector.crash_pos)
                self._run_query(cluster, cursor, crash_dml_burst, 1, True)
                if bg_commit == "True":
                    cluster.run_xpx('hello')
            except Exception as e:
                log.info("error message: " + str(e))
                assert "non-std exception" in str(e)

            log.info("reboot cluster start")
            cluster.reboot_cluster()

        cluster.wait_for_cluster_available(180)
        # Restart super simulated mode after restart
        if cluster.host_type != HostType.CLUSTER:
            prepare_burst(BURST_GUCS)
            backup_id = 'test_backup_{}'.format(str(uuid.uuid4()))
            create_localhost_snapshot(backup_id, wait=True)
            cold_start(backup_id)
            log.info("Restart super simulated Burst cluster is ready.")

        self._start_and_wait_for_refresh(cluster)
        with db_session_master.cursor() as cursor, \
                db_session.cursor() as cursor_bs:
            if cluster.host_type != HostType.CLUSTER:
                cursor_bs.execute(fixed_slice_unset)
            self._validate_table_data(cluster, cursor, vector.diststyle)
            self._validate_identity_column_data(cluster, cursor,
                                                "burst_tbl_burst")

        # Generates new id col values after restart
        # and make sure they are unique
        with db_session_master.cursor() as cursor:
            self._insert_tables(cluster, cursor)
            self.insert_select(cluster, cursor, "burst", 2, True)
            self._validate_identity_column_data(cluster, cursor,
                                                "burst_tbl_burst")


@pytest.mark.encrypted_only
@pytest.mark.serial_only
@pytest.mark.localhost_only
@pytest.mark.skip_load_data
@pytest.mark.super_simulated_mode
@pytest.mark.custom_burst_gucs(gucs=BURST_GUCS)
@pytest.mark.custom_local_gucs(gucs={'burst_enable_write_id_col': 'true'})
@pytest.mark.usefixtures("super_simulated_mode")
@pytest.mark.session_ctx(user_type='bootstrap')
@pytest.mark.super_simulated_precommit
class TestBurstWriteIDColRestartSS(BurstWriteIDColRestartBase):
    @classmethod
    def modify_test_dimensions(cls):
        return Dimensions(
            dict(
                diststyle=['distkey(c0)', 'diststyle even'],
                sortkey=['sortkey(c0)'],
                crash_pos=['EtCrashCommitBeforeP1', 'EtCrashCommitAfterP1'],
                crash_dml=['insert', 'insert_select', 'update', 'delete'],
            ))

    @pytest.mark.parametrize("bg_commit", ['True'])
    def test_bw_id_col_restart(self, db_session, vector, cluster, bg_commit):
        self.base_bw_id_col_restart(db_session, vector, cluster, bg_commit)
