# Copyright 2021 Amazon.com, Inc. or its affiliates
# All Rights Reserved

import pytest
import logging
from raff.burst.burst_test import (BurstTest, setup_teardown_burst,
                                   verify_query_didnt_burst,
                                   verify_all_queries_bursted)
from raff.common.cred_helper import get_role_auth_str
from raff.common.profile import AwsAccounts
from raff.common.aws_clients.redshift_client import RedshiftClient
from raff.common.profile import Profiles
from raff.common.region import Regions
from raff.datasharing.datasharing_test import (
    DatasharingBurstTest, consumer_cluster, consumer_session_ext_only,
    datashare_context, datashare_setup, setup_teardown_burst_datasharing,
    customise_burst_cluster_datasharing, verify_query_burst_datasharing,
    verify_query_didnt_burst_datasharing,
    verify_all_queries_bursted_datasharing)
log = logging.getLogger(__name__)

# Point to existing consumer cluster.
# Remove if we have a preferered runnable.
# pytestmark = pytest.mark.consumer_cluster_existing(
#     existing_identifier='chunbin-consumer')

CONSUMER_CLUSTER_GUCS = dict(
    enable_burst_datasharing='true',
    enable_burst_datasharing_volt_tt='true',
    enable_burst_async_acquire='false',
    burst_volt_tts_require_replay='false',
    enable_burst_failure_handling='true',
    burst_disable_volt_tts_on_failure='false',
    burst_enable_volt_tts='true')

BURST_CLUSTER_GUCS = dict(
    enable_burst_datasharing='true',
    enable_burst_datasharing_volt_tt='true',
    enable_data_sharing_result_cache='false',
    diff_topologies_mode='2',
    enable_redcat_table_integration='true',
    enable_redshift_federation='true',
    use_s3commit_in_rslocal_federation='true')

TPCDS_Q1_SQL = """
      {}
      WITH /* TPC-DS query1.tpl 0.12 */ customer_total_return AS
          (SELECT sr_customer_sk AS ctr_customer_sk,
                  sr_store_sk AS ctr_store_sk,
                  sum(SR_STORE_CREDIT) AS ctr_total_return
           FROM devpublic.store_returns,
                devpublic.date_dim
           WHERE sr_returned_date_sk = d_date_sk
             AND d_year =2000
           GROUP BY sr_customer_sk,
                    sr_store_sk)
        SELECT /* TPC-DS query1.tpl 0.12 */ top 100 c_customer_id
        FROM customer_total_return ctr1,
             devpublic.store,
             devpublic.customer
        WHERE ctr1.ctr_total_return >
            (SELECT avg(ctr_total_return)*1.2
             FROM customer_total_return ctr2
             WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk)
          AND s_store_sk = ctr1.ctr_store_sk
          AND s_state = 'MI'
          AND ctr1.ctr_customer_sk = c_customer_sk
        ORDER BY c_customer_id;
"""


@pytest.mark.serial_only
@pytest.mark.cluster_only
@pytest.mark.custom_burst_gucs(gucs=CONSUMER_CLUSTER_GUCS)
@pytest.mark.usefixtures("customise_burst_cluster_datasharing")
@pytest.mark.customise_burst_cluster_args(BURST_CLUSTER_GUCS)
class TestDsBurstVoltTTFailureNoReplay(DatasharingBurstTest):
    """
    Tests that failures when Bursting Volt TTs are not retried but propagated to
    the user. This does not apply to the first CTAS generated by the Volt query
    though because it does not create any state on the Burst cluster.
    """

    def get_burst_cluster(self, burst_cluster_arn):
        profile_obj = Profiles.get_by_name(Profiles.QA_BURST_TEST.name)
        burst_client = RedshiftClient(profile=profile_obj, region=Regions.QA)
        burst_cluster_name = burst_cluster_arn.split(':cluster:')[-1].strip()
        burst_cluster = burst_client.describe_cluster(burst_cluster_name)
        return burst_cluster

    def test_ds_burst_volt_tt_failure_no_replay(
            self, cluster, consumer_cluster, consumer_session_ext_only,
            s3_client):
        # Setup
        burst_cluster_arns = consumer_cluster.list_acquired_burst_clusters()
        burst_cluster = self.get_burst_cluster(burst_cluster_arns[0])
        IAM_CREDENTIAL = get_role_auth_str(
            AwsAccounts.DP.iam_roles.Redshift_S3_Write)
        TEST_S3_PATH = ("s3://cookie-monster-s3-ingestion/"
                        "raff_test_burst_unload/{}/{}/")

        # Ensure that the queries succeed if we fail the first Volt-generated
        # CTAS.
        burst_cluster.set_event('EtFailNthBurstQueries,frequency={}'.format(1))
        # Prepare
        with self.burst_db_cursor(consumer_session_ext_only) as cursor:
            cursor.execute(TPCDS_Q1_SQL.format("PREPARE p1 AS "))
            cursor.execute("EXECUTE p1;")
            assert cursor.fetchall() == []
            cursor.execute("DEALLOCATE p1;")
        # Unload
        rand_str = self._generate_random_string()
        unload_path = TEST_S3_PATH.format('volt_tt_failure_no_replay',
                                          rand_str)
        with self.unload_session(unload_path, s3_client):
            with self.burst_db_cursor(consumer_session_ext_only) as cursor:
                # Note: UNLOAD does not support LIMIT.
                cursor.run_unload(
                    TPCDS_Q1_SQL.format("").replace("\'", "\\'").replace(
                        " top 100", ""), unload_path, IAM_CREDENTIAL)
                assert cursor.last_unload_row_count() == 0

        # Ensure that the queries fail if we fail the second and final query.
        error_msg = '.*Simulated Burst query failure.*'
        burst_cluster.set_event('EtFailNthBurstQueries,frequency={}'.format(2))
        # Prepare
        with self.burst_db_cursor(consumer_session_ext_only) as cursor:
            cursor.execute(TPCDS_Q1_SQL.format("PREPARE p1 AS "))
            self.execute_failing_query("EXECUTE p1;", error_msg,
                                       consumer_session_ext_only)
            cursor.execute("DEALLOCATE p1;")

        # Unload
        rand_str = self._generate_random_string()
        unload_path = TEST_S3_PATH.format('volt_tt_failure_no_replay',
                                          rand_str)
        with self.unload_session(unload_path, s3_client):
            with self.burst_db_cursor(consumer_session_ext_only) as cursor:
                # Note: UNLOAD does not support LIMIT.
                self.execute_failing_unload(
                    select_stmt=TPCDS_Q1_SQL.format("").replace(
                        "\'", "\\'").replace(" top 100", ""),
                    data_dest=unload_path,
                    error_regex=error_msg,
                    auth=IAM_CREDENTIAL,
                    session=consumer_session_ext_only)
