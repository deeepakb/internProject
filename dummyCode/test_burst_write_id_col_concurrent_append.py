# Copyright 2021 Amazon.com, Inc. or its affiliates
# All Rights Reserved
import logging
import pytest
import time

from test_burst_write_id_col_commit import BurstWriteIdentityColumnBase
from raff.burst.burst_super_simulated_mode_helper import super_simulated_mode
from raff.common.dimensions import Dimensions
from raff.storage.storage_test import create_thread
from raff.common.db.session import DbSession

__all__ = [super_simulated_mode]
log = logging.getLogger(__name__)
INSERT_STMT_T1 = "insert into {}.bw_t1(c0) values(10);"
INSERT_STMT_T2 = "insert into {}.bw_t2(c0,c2) values(10, 10);"
ALTER_APPEND_STMT = ("ALTER TABLE {schema}.bw_t1 "
                     "APPEND FROM {schema}.bw_t2 FILLTARGET;")
INSERT_SELECT_STMT_1 = (
    "insert into {schema}.bw_t1(c0) select c0 from {schema}.bw_t2;")
INSERT_SELECT_STMT_2 = (
    "insert into {schema}.bw_t2(c0,c2) select c0,c2 from {schema}.bw_t1;")
PG_CLASS_OID_LOOKUP = "select oid from pg_class where relname = '{}';"
LOCKS_LOOKUP = ("select distinct granted from pg_locks where relation = '{}'"
                " and mode = 'ShareRowExclusiveLock';")
MAIN_OWNED = [('Main', 'Owned')]
MAIN_UNDO = [('Main', 'Undo')]
BURST_OWNED = [('Burst', 'Owned')]


@pytest.mark.serial_only
@pytest.mark.localhost_only
@pytest.mark.skip_load_data
@pytest.mark.super_simulated_mode
@pytest.mark.usefixtures("super_simulated_mode")
@pytest.mark.custom_burst_gucs(
    gucs={
        'slices_per_node': '4',
        'burst_enable_write': 'true',
        'burst_enable_write_id_col': 'true'
    })
@pytest.mark.custom_local_gucs(gucs={'burst_enable_write_id_col': 'true'})
class TestBurstWriteIdColConcurrentAlterAppend(BurstWriteIdentityColumnBase):
    @classmethod
    def modify_test_dimensions(cls):
        return Dimensions({
            "guard": [
                'burst:check_backup', 'burst:find_cluster',
                'burst:found_cluster', 'burst_write:pre_write_lock'
            ],
            "is_owned_table": [True, False]
        })

    def _setup_tables(self, db_session, schema):
        with db_session.cursor() as cursor:
            cursor.execute("begin;")
            cursor.execute(
                "create table bw_t1(c0 int, c1 bigint identity(0, 1),"
                "c2 BIGINT GENERATED BY DEFAULT AS IDENTITY NOT NULL)"
                " diststyle even;")
            cursor.execute("create table bw_t2(c0 int, c2 BIGINT NOT NULL)"
                           " diststyle even;")
            cursor.execute("select * from bw_t1;")
            cursor.execute("select * from bw_t2;")
            cursor.execute("insert into bw_t1(c0, c2) "
                           "values(0, -10),(1, -10),(2, -10),(3, -10)")
            cursor.execute("insert into bw_t2(c0, c2) "
                           "values(0, 1),(1, 2),(2, 3),(3, 4)")
            for i in range(10):
                cursor.execute("insert into bw_t1(c0) select c0 from bw_t1;")
                cursor.execute("insert into bw_t2(c0, c2) "
                               "select c0,c2 from bw_t2;")
            cursor.execute("commit;")

    def _init_check(self, cluster, cursor, schema):
        self._validate_identity_column_data(cluster, cursor)
        self._validate_ownership_state(schema, 'bw_t1', [])
        self._validate_ownership_state(schema, 'bw_t2', [])
        # make burst cluster owns bw_t1 and bw_t2
        cursor.execute("set query_group to burst;")
        cursor.execute("begin;")
        cursor.execute("insert into bw_t1(c0) values(0),(1),(2),(3)")
        self._check_last_query_bursted(cluster, cursor)
        self._validate_ownership_state(schema, 'bw_t1', BURST_OWNED)
        cursor.execute("insert into bw_t2(c0, c2) "
                       "values(0, 1),(1, 2),(2, 3),(3, 4)")
        self._check_last_query_bursted(cluster, cursor)
        self._validate_ownership_state(schema, 'bw_t2', BURST_OWNED)
        cursor.execute("commit")
        self._validate_ownership_state(schema, 'bw_t1', BURST_OWNED)
        self._validate_ownership_state(schema, 'bw_t2', BURST_OWNED)

    def _do_background_query(self, cluster, cursor, schema, query, is_bursted):
        if is_bursted:
            cursor.execute('set query_group to burst;')
        else:
            cursor.execute('set query_group to metric;')
        cursor.execute(query.format(schema=schema))
        if is_bursted:
            self._check_last_query_bursted(cluster, cursor)
        else:
            self._check_last_query_didnt_burst(cluster, cursor)

    def _close_test(self, cluster, cursor, schema):
        cursor.execute("insert into bw_t1(c0) values(10)")
        self._check_last_query_bursted(cluster, cursor)
        cursor.execute("insert into bw_t2(c0, c2) values(10, 10)")
        self._check_last_query_bursted(cluster, cursor)
        self._validate_ownership_state(schema, 'bw_t1', BURST_OWNED)
        self._validate_ownership_state(schema, 'bw_t2', BURST_OWNED)
        self._validate_table(cluster, schema, 'bw_t1', 'even')
        self._validate_table(cluster, schema, 'bw_t2', 'even')
        cursor.execute("drop table bw_t1;")
        cursor.execute("drop table bw_t2;")

    def _should_burst(self, vector, is_commit):
        return (vector.guard == 'burst:found_cluster' or
                not vector.is_owned_table) and \
               (is_commit or vector.guard != 'burst_write:pre_write_lock')

    def _validate_identity_column_data(self, cluster, cursor):
        self._start_and_wait_for_refresh(cluster)
        self._check_duplicated_id_col_values(cursor, "bw_t1", "c1", "(-10)",
                                             True)
        self._check_duplicated_id_col_values(cursor, "bw_t1", "c2",
                                             "(-10,1,2,3,4)", True)

    def _get_table_oid(self, table):
        query = PG_CLASS_OID_LOOKUP.format(table)
        with self.db.cursor() as bootstrap_cursor:
            bootstrap_cursor.execute(query)
            result = bootstrap_cursor.fetch_scalar()
        return result

    def _get_table_locks(self, cluster, table_id):
        query = LOCKS_LOOKUP.format(table_id)
        db_session = DbSession(cluster.get_conn_params())
        with db_session.cursor() as bootstrap_cursor:
            bootstrap_cursor.execute("set query_group to metric;")
            bootstrap_cursor.execute(query)
            result = bootstrap_cursor.fetchall()
        return result

    def _commit_dml(self, schema, xen_guard, concurrent_thread):
        with self.db.cursor() as bootstrap_cursor:
            bootstrap_cursor.execute("xpx 'event set EtBurstWriteGuard'")
            bootstrap_cursor.execute(ALTER_APPEND_STMT.format(schema=schema))
            self._validate_ownership_state(schema, 'bw_t2', MAIN_OWNED)
            xen_guard.disable()
            concurrent_thread.join()
            self._validate_ownership_state(schema, 'bw_t2', [])
            bootstrap_cursor.execute("xpx 'event unset EtBurstWriteGuard'")

    @pytest.mark.skip(reason="DP-36680")
    def test_bw_id_col_with_concurrent_alter_append(self, cluster, vector,
                                                    db_session):
        """
        Test: Block write query on different burst qualification position and
              commit dml on owned tables in background. Check the burst
              qualification works correctly.
        """
        schema = db_session.session_ctx.schema
        with db_session.cursor() as cursor, self.db.cursor() as cursor_2:
            cursor.execute("set query_group to burst;")
            self._setup_tables(db_session, schema)
            self._start_and_wait_for_refresh(cluster)
            if vector.is_owned_table:
                self._init_check(cluster, cursor, schema)
            burst_select_params = (cluster, cursor, schema,
                                   INSERT_SELECT_STMT_1, True)
            alter_append_params = (cluster, cursor_2, schema,
                                   ALTER_APPEND_STMT, False)
            bw_t1_oid = self._get_table_oid("bw_t1")
            with create_thread(self._do_background_query,
                               burst_select_params) as thread_burst, \
                 create_thread(self._do_background_query,
                               alter_append_params) as thread_append, \
                    self._create_xen_guard(vector.guard) as xen_guard:
                thread_burst.start()
                xen_guard.wait_until_process_blocks()
                log.info("ALTER APPEND thread started")
                thread_append.start()
                # check alter append is blocked by concurrent burst queries
                # ShareRowExclusiveLock should be acquired in burst thread
                # and alter append thread should be waiting on the lock.
                locks_res = self._get_table_locks(cluster, bw_t1_oid)
                wait_time = 0
                # Wait at least 30 seconds for alter append to be blocked
                while len(locks_res) < 2 and wait_time < 180:
                    locks_res = self._get_table_locks(bw_t1_oid)
                    log.info("Locks status: {}".foramt(locks_res))
                    time.sleep(1)
                    wait_time = wait_time + 1
                assert len(locks_res) > 1
                # unblock all threads
                xen_guard.disable()
                thread_burst.join()
                thread_append.join()
            # Since alter append query on bw_t1 is ran on main cluster,
            # then bw_t1's state is empty.
            self._validate_ownership_state(schema, 'bw_t1', [])
            # Since write query on bw_t2 is ran on main cluster, then bw_t2's
            # state is empty.
            self._validate_ownership_state(schema, 'bw_t2', [])
            self._start_and_wait_for_refresh(cluster)
            # check table ownership after backup and refresh.
            self._validate_ownership_state(schema, 'bw_t1', [])
            self._validate_ownership_state(schema, 'bw_t2', [])
            # check burst cluster table content
            cursor.execute("set query_group to burst;")
            cursor.execute(INSERT_SELECT_STMT_1.format(schema=schema))
            self._validate_identity_column_data(cluster, cursor)
            cursor.execute("set query_group to burst;")
            self._close_test(cluster, cursor, schema)
