# Copyright 2022 Amazon.com, Inc. or its affiliates
# All Rights Reserved
import logging
import pytest
import datetime
import time
import uuid

from test_burst_write_id_col_commit import BurstWriteIdentityColumnBase
from raff.common.simulated_helper import create_localhost_snapshot
from raff.common.base_test import (run_priviledged_query_scalar_int,
                                   run_priviledged_query)
from raff.burst.burst_super_simulated_mode_helper import super_simulated_mode

__all__ = [super_simulated_mode]
log = logging.getLogger(__name__)
INSERT_STMT_T1 = "insert into bw_t1(c0) values(10);"
INSERT_STMT_T2 = "insert into bw_t2(c0) values(10);"
INSERT_SELECT_STMT = ("insert into bw_t1(c0) select c0 from bw_t1;")
MAIN_OWNED = [('Main', 'Owned')]
MAIN_UNDO = [('Main', 'Undo')]
BURST_OWNED = [('Burst', 'Owned')]


@pytest.mark.serial_only
@pytest.mark.localhost_only
@pytest.mark.skip_load_data
@pytest.mark.super_simulated_mode
@pytest.mark.usefixtures("super_simulated_mode")
@pytest.mark.custom_burst_gucs(
    gucs={
        'slices_per_node': '8',
        'burst_enable_write': 'true',
        'burst_enable_write_id_col': 'true'
    })
@pytest.mark.custom_local_gucs(gucs={'burst_enable_write_id_col': 'true'})
class TestBurstWriteIdColConcurrentRefresh(BurstWriteIdentityColumnBase):
    def _setup_tables(self, db_session):
        with db_session.cursor() as cursor:
            cursor.execute("begin;")
            cursor.execute(
                "create table bw_t1(c0 int, c1 bigint identity(0, 1),"
                "c2 BIGINT GENERATED BY DEFAULT AS IDENTITY NOT NULL)"
                " diststyle even;")
            cursor.execute(
                "create table bw_t2(c0 int, c1 bigint identity(0, 1),"
                "c2 BIGINT GENERATED BY DEFAULT AS IDENTITY NOT NULL)"
                " diststyle even;")
            cursor.execute("select * from bw_t1;")
            cursor.execute("select * from bw_t2;")
            cursor.execute("insert into bw_t1(c0) values(0),(1),(2),(3)")
            cursor.execute("insert into bw_t2(c0) values(0),(1),(2),(3)")
            for i in range(3):
                cursor.execute("insert into bw_t1(c0) select c0 from bw_t1;")
                cursor.execute("insert into bw_t2(c0) select c0 from bw_t2;")
            cursor.execute("commit;")

    def _init_check(self, cluster, cursor, schema):
        self._validate_identity_column_data(cluster, cursor)
        self._validate_ownership_state(schema, 'bw_t1', [])
        self._validate_ownership_state(schema, 'bw_t2', [])
        # make burst cluster owns bw_t1 and bw_t2
        cursor.execute("set query_group to burst;")
        cursor.execute("begin;")
        cursor.execute("insert into bw_t1(c0) values(0),(1),(2),(3)")
        self._check_last_query_bursted(cluster, cursor)
        self._validate_ownership_state(schema, 'bw_t1', BURST_OWNED)
        cursor.execute("insert into bw_t2(c0) values(0),(1),(2),(3)")
        self._check_last_query_bursted(cluster, cursor)
        self._validate_ownership_state(schema, 'bw_t2', BURST_OWNED)
        cursor.execute("commit")
        self._validate_ownership_state(schema, 'bw_t1', BURST_OWNED)
        self._validate_ownership_state(schema, 'bw_t2', BURST_OWNED)

    def _do_background_query(self, cluster, cursor, schema, query, is_bursted):
        cursor.execute('set query_group to burst;')
        cursor.execute(query)
        if is_bursted:
            self._check_last_query_bursted(cluster, cursor)
        else:
            self._check_last_query_didnt_burst(cluster, cursor)

    def _close_test(self, cluster, cursor, schema):
        cursor.execute("insert into bw_t1(c0) values(10)")
        self._check_last_query_bursted(cluster, cursor)
        cursor.execute("insert into bw_t2(c0) values(10)")
        self._check_last_query_bursted(cluster, cursor)
        self._validate_ownership_state(schema, 'bw_t1', BURST_OWNED)
        self._validate_ownership_state(schema, 'bw_t2', BURST_OWNED)
        cursor.execute("drop table bw_t1;")
        cursor.execute("drop table bw_t2;")

    def _validate_identity_column_data(self, cluster, cursor):
        self._start_and_wait_for_refresh(cluster)
        self._check_duplicated_id_col_values(cursor, "bw_t1", "c1", "(-10)",
                                             True)
        self._check_duplicated_id_col_values(cursor, "bw_t1", "c2", "(-10)",
                                             True)

    def _concurrent_refresh(self, cluster, xen_guard, concurrent_thread):
        with self.db.cursor() as bootstrap_cursor:
            bootstrap_cursor.execute("xpx 'event set EtBurstWriteGuard'")
            self._refresh_without_backup(cluster)
            xen_guard.disable()
            concurrent_thread.join()
            bootstrap_cursor.execute("xpx 'event unset EtBurstWriteGuard'")

    def _refresh_without_backup(self, cluster):
        start_time = datetime.datetime.now().replace(microsecond=0)
        start_str = start_time.isoformat(' ')
        with self.db.cursor() as cursor:
            query = ("select max(sb_version) from stl_backup_leader "
                     "where in_progress = 0;")
            sb_version = run_priviledged_query_scalar_int(
                cluster, cursor, query)
            log.info("Refresh without backup, Latest sb_version {}".format(
                sb_version))

            cluster.run_xpx('burst_start_refresh')
            query_start = """select * from stl_burst_manager_refresh
                                where action in ('RefreshStart',
                                                'RefreshInProgress') and
                                    refresh_version >= {} and
                                eventtime >= '{}';""".format(
                sb_version, start_str)
            timeout = time.time() + 300
            results = []
            while time.time() <= timeout and len(results) == 0:
                self._check_and_start_personalization(cluster)
                cluster.run_xpx('burst_start_refresh')
                time.sleep(1)
                results = run_priviledged_query(cluster, cursor, query_start)
                log.info("start_and_wait_for_refresh first check: {}".format(
                    results))

            if len(results) == 0:
                return

            query_end = """select * from stl_burst_manager_refresh
                            where action = 'RefreshEnd' and
                                    refresh_version >= {} and
                                    eventtime >= '{}';""".format(
                sb_version, start_str)
            timeout = time.time() + 300
            results = []
            while time.time() <= timeout and len(results) == 0:
                time.sleep(1)
                results = run_priviledged_query(cluster, cursor, query_end)
                log.info("start_and_wait_for_refresh second check: {}".format(
                    results))

    def gen_id_values_all_slices(self, schema, cursor):
        slice_blk_check = (
            "select distinct slice from stv_blocklist "
            "where num_values > 0 and tbl='{}.bw_t1'::regclass::oid "
            "and col = 1 order by 1;").format(schema)
        cursor.execute('set query_group to burst;')
        with self.db.cursor() as cursor_bs:
            cursor_bs.execute(slice_blk_check)
            res = cursor_bs.fetchall()
            while len(res) < 6:
                log.info(
                    "Current bw_t1 slices that contains values: " + str(res))
                cursor.execute('set query_group to burst;')
                cursor.execute("insert into bw_t1(c0) values(0),(1),(2),(3)")
                cursor_bs.execute(slice_blk_check)
                res = cursor_bs.fetchall()
            cursor.execute("insert into bw_t1(c0) select c0 from bw_t1")
            cursor_bs.execute(slice_blk_check)
            res = cursor_bs.fetchall()
            log.info("Final bw_t1 slices that contains values: " + str(res))

    def test_bw_id_col_with_concurrent_refresh(self, cluster, db_session):
        """
        Test: Block write query on different burst qualification position and
              trigger refresh in background. Check the burst
              qualification and high watermark works correctly.
        """
        schema = db_session.session_ctx.schema
        with db_session.cursor() as cursor:
            cursor.execute("set query_group to burst;")
            self._setup_tables(db_session)
            self._start_and_wait_for_refresh(cluster)
            self._init_check(cluster, cursor, schema)
            # backup on unrelated table t2
            cursor.execute("set query_group to metric;")
            cursor.execute(INSERT_STMT_T2)
            snapshot_id = "burst-write-snapshot-{}".format(
                str(uuid.uuid4().hex))
            log.info("stale backup created: " + snapshot_id)
            create_localhost_snapshot(snapshot_id, wait=True)
            # Make sure all slices in t1 contains new id values from burst
            self.gen_id_values_all_slices(schema, cursor)
            # Refresh back to old version
            self._refresh_without_backup(cluster)
            # Trigger insert on wrong sb version
            cursor.execute(INSERT_STMT_T1)
            # Since it is write query, bw_t1 is in BURST_OWNED state only if
            # the write query is burted.
            self._validate_ownership_state(schema, 'bw_t1', BURST_OWNED)
            self._start_and_wait_for_refresh(cluster)
            # check table ownership after backup and refresh.
            self._validate_ownership_state(schema, 'bw_t1', BURST_OWNED)
            # check burst cluster table content
            cursor.execute("set query_group to burst;")
            cursor.execute(INSERT_SELECT_STMT)
            self._validate_identity_column_data(cluster, cursor)
            cursor.execute("set query_group to burst;")
            log.info("Test Done")
            self._close_test(cluster, cursor, schema)
