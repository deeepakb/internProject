# Copyright 2024 Amazon.com, Inc. or its affiliates
# All Rights Reserved
import logging
import pytest
import datetime

from psycopg2.extensions import QueryCanceledError
from psycopg2 import OperationalError
from raff.burst.burst_super_simulated_mode_helper import super_simulated_mode
from raff.burst.burst_write import BurstWriteTest
from raff.common.db.session import DbSession
from raff.storage.storage_test import create_thread
from py_lib.common.xen_guard_control import localhost_xen_guard
from raff.common.dimensions import Dimensions

log = logging.getLogger(__name__)
__all__ = [super_simulated_mode]

CREATE_ID_COL_TBL = (
    "CREATE TABLE public.test_tbl (c1 int, c2 int GENERATED BY "
    "DEFAULT AS identity(11, 2) encode RAW) diststyle EVEN;"
)
INSERT = "insert into test_tbl(c1, c2) values(1, default);"
DELETE = 'DELETE FROM test_tbl WHERE c1=1;'
PG_CANCEL = "select pg_cancel_backend({});"
GUARD = "guard_after_gen_id_vals"


@pytest.mark.serial_only
@pytest.mark.localhost_only
@pytest.mark.skip_load_data
@pytest.mark.super_simulated_mode
@pytest.mark.custom_local_gucs(gucs={
    'burst_enable_write_id_col': 'true',
    'enable_sync_max_id_on_abort': 'true'
})
@pytest.mark.custom_burst_gucs(gucs={'burst_enable_write_id_col': 'true'})
@pytest.mark.usefixtures("super_simulated_mode")
class TestBurstIdColSync(BurstWriteTest):
    @classmethod
    def modify_test_dimensions(cls):
        """Dimensions for cancelling a query.

        Returns:
            The new test parameter.
        """
        return Dimensions({
            "cancel_cmd": [
                "select pg_cancel_backend({})",
                "select pg_terminate_backend({})"
            ]
        })

    @classmethod
    def create_xen_guard(cls, name):
        """Create xen_guard object.

        Args:
            name (str): Name of the xen_guard.

        Returns:
            XenGuardControl instance with the provided name.
        """
        return localhost_xen_guard(name)

    def _get_table_oid(self, table):
        """Returns table id given the table name.

        Args:
            table (str): table name

        Returns:
            int: table id
        """
        with self.db.cursor() as curs:
            curs.execute("select '{}'::regclass::oid".format(table))
            return curs.fetch_scalar()

    def _setup_table(self, cursor, cluster):
        """Setup the id col table for testing.

        Args:
            cursor (RedshiftCursor): Cursor to execute the queries.
            cluster (ClusterSession): a cluster object.
        """
        tbl_def = (CREATE_ID_COL_TBL)
        cursor.execute(tbl_def)
        cursor.execute("set query_group to noburst")
        for i in range(50):
            cursor.execute(
                "insert into test_tbl(c1, c2) values({}, default);".format(i))
        for i in range(2):
            cursor.execute("insert into test_tbl select * from test_tbl")

    def _run_insert_on_main(self, cursor):
        """Run an insert query on the main cluster.

        Args:
            cursor (RedshiftCursor): Cursor to execute the query.
        """
        cursor.execute('set query_group to noburst;')
        cursor.execute(INSERT)

    def _run_delete_on_burst(self, cursor):
        """Run a delete query on the burst cluster.

        Args:
            cursor (RedshiftCursor): Cursor to execute the query.
        """
        cursor.execute('set query_group to burst')
        cursor.execute(DELETE)

    def _get_insert_pid(self, cursor, starttime):
        """Get the running insert query pid from stv_inflight.

        Args:
            cursor (RedshiftCursor): Cursor to execute the query.
            starttime (datetime): Starttime after setup, before insert query to abort.

        Returns:
            int: query pid
        """
        query = ("select pid from stv_inflight where userid>1 and text like '%{}%' "
                 "and starttime > '{}'")
        cursor.execute(query.format(INSERT, starttime))
        return cursor.fetch_scalar()

    def _cancel_insert(self, cursor, cmd, starttime):
        """Cancel running insert query.

        Args:
            cmd (str): Cancel command to perform (cancel or terminate).
            starttime (datetime): starttime of the insert query thread.
        """
        with self.db.cursor() as boot_cursor:
            pid = self._get_insert_pid(boot_cursor, starttime)
        cursor.execute(cmd.format(pid))

    def _issue_two_dummy_commits(self, cursor):
        """Issue two dummy commits by creating two new tables.
           This is necessary to make a table eligible for bursting
           after an undo on that table has been performed.

        Args:
            cursor (RedshiftCursor): Cursor to execute the queries.
        """
        cursor.execute('create table public.t1 (a int);')
        cursor.execute('create table public.t2 (a int);')

    def _cleanup_test_tables(self, cursor):
        """Drop test tables for the next dimension.

        Args:
            cursor (RedshiftCursor): Cursor to execute the queries.
        """
        cursor.execute("DROP TABLE IF EXISTS test_tbl")
        cursor.execute("DROP TABLE IF EXISTS t1")
        cursor.execute("DROP TABLE IF EXISTS t2")

    def _get_current_watermarks(self, cursor):
        """Get the current high watermarks of the test table on the
           compute nodes. This will be used to validate watermarks
           have been updated afater the cancel.

        Args:
            cursor (RedshiftCursor): Cursor to execute the query.

        Returns:
            List of high watermarks on the compute nodes.
        """
        oid = self._get_table_oid("test_tbl")
        query = (
            "select highwater, slice from stv_identity_highwater where tbl = {}"
            " order by 2;")
        cursor.execute(query.format(oid))
        return [value[0] for value in cursor.fetchall()]

    def test_burst_id_col_sync(self, cluster, vector):
        """This test performs the following steps:
            1. Creates a table with identity columns and inserts data.
            2. Runs insert query to generate high watermarks on main LN.
               Pause the query after the new watermarks are generated but
               before the LN can sync with the CNs.
            3. Abort the insert query. If all goes well we will see the
               LN still sync with the CNs during the abort.
            4. Issue two dummy commits after undo so the table is eligible
               for bursting again.
            4. Run a delete query with this table on burst. Returning
               watermarks should be correct meaning the same or greater
               than the watermarks on main LN.

        Args:
            cluster (ClusterSession): a cluster object.
            vector (dimensions): test parameters.
        """
        db_session = DbSession(cluster.get_conn_params(user='master'))
        xen_guard = self.create_xen_guard(GUARD)
        with self.db.cursor() as boot_curs:
            with db_session.cursor() as cursor:
                self._setup_table(cursor, cluster)
                starttime = datetime.datetime.now()
                boot_curs.execute(
                    "GRANT ALL ON ALL TABLES IN SCHEMA public TO public;")
                # Get watermarks before query is aborted.
                pre_abort_wm = self._get_current_watermarks(boot_curs)
                try:
                    with create_thread(self._run_insert_on_main,
                                       (cursor, )) as thread, xen_guard:
                        cluster.set_event('EtPauseAfterGenIdVals')
                        thread.start()
                        xen_guard.wait_until_process_blocks()
                        self._cancel_insert(boot_curs, vector.cancel_cmd,
                                            starttime)
                # exception caused by pg_cancel_backend()
                except QueryCanceledError as e:
                    assert "cancelled on user's request" in str(e)
                # exception caused by pg_terminate_backend()
                except OperationalError as e:
                    assert "terminating connection" in str(e)
                finally:
                    cluster.unset_event('EtPauseAfterGenIdVals')

            # Get watermarks after the query has been aborted.
            post_abort_wm = self._get_current_watermarks(boot_curs)
            # Check if watermarks have been updated.
            assert sum(pre_abort_wm) < sum(post_abort_wm), \
                "Watermarks have not been updated"

            # We create a new session in the case the previous
            # one was closed due to pg_terminate_backend().
            with db_session.cursor() as cursor:
                self._issue_two_dummy_commits(cursor)
                self._start_and_wait_for_refresh(cluster)
                self._run_delete_on_burst(cursor)
                self.check_last_query_bursted(cluster, cursor)

                self._cleanup_test_tables(cursor)
