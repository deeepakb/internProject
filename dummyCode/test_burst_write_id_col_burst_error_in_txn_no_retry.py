# Copyright 2020 Amazon.com, Inc. or its affiliates
# All Rights Reserved
import logging
import datetime
import pytest
import uuid
from contextlib import contextmanager

from raff.burst.burst_super_simulated_mode_helper import (
    super_simulated_mode_method, get_burst_conn_params)
from raff.common.dimensions import Dimensions
from raff.common.db.redshift_db import RedshiftDb
from raff.storage.storage_test import disable_all_autoworkers
from test_burst_write_id_col_commit import BurstWriteIdentityColumnBase

log = logging.getLogger(__name__)
__all__ = [super_simulated_mode_method, disable_all_autoworkers]

INSERT_CMD = 'insert into {}(c0, c2) values(10, DEFAULT);'
INSERT_SELECT_CMD = 'insert into {}(c0) select c0 from {};'
DELETE_CMD = 'delete from {} where c0 % 3 = 2;'
UPDATE_CMD = "UPDATE {} set c0 = c0 + 1, c2 = c2 - 2;"

burst_write_no_retry_gucs = {
    'burst_enable_write_id_col': 'true',
    'enable_burst_failure_handling': 'false',
    'burst_enable_insert_failure_handling': 'false',
    'burst_enable_delete_failure_handling': 'false',
    'burst_enable_update_failure_handling': 'false',
    'burst_enable_copy_failure_handling': 'false'
}

burst_write_retry_gucs = {
    'burst_enable_write_id_col': 'true',
    'enable_burst_failure_handling': 'true',
    'burst_enable_insert_failure_handling': 'true',
    'burst_enable_delete_failure_handling': 'true',
    'burst_enable_update_failure_handling': 'true',
    'burst_enable_copy_failure_handling': 'true'
}


class BaseBurstIDColClusterError(BurstWriteIdentityColumnBase):
    def _setup_table(self, tbl_name, cursor, vector):
        diststyle = vector.diststyle
        sortkey = vector.sortkey
        tbl_def_burst = (
            "create table {}(c0 int, c1 bigint identity(0, 1),"
            "c2 BIGINT GENERATED BY DEFAULT AS IDENTITY NOT NULL) {} {};")
        cursor.execute("begin;")
        cursor.execute(tbl_def_burst.format(tbl_name, diststyle, sortkey))
        for i in range(3):
            cursor.execute(INSERT_CMD.format(tbl_name))
            cursor.execute(INSERT_SELECT_CMD.format(tbl_name, tbl_name))
        cursor.execute("commit;")

    def _generate_dml_cmd(self, vector, tbl_name):
        if vector.dml == 'insert':
            return INSERT_CMD.format(tbl_name)
        elif vector.dml == 'insert_select':
            return INSERT_SELECT_CMD.format(tbl_name, tbl_name)
        elif vector.dml == 'delete':
            return DELETE_CMD.format(tbl_name)
        elif vector.dml == 'update':
            return UPDATE_CMD.format(tbl_name)

    def _run_query_check_bursted(self, cluster, cursor, query, burst):
        if burst:
            cursor.execute("set query_group to burst;")
        else:
            cursor.execute("set query_group to metrics;")
        cursor.execute(query)
        if burst:
            self._check_last_query_bursted(cluster, cursor)
        else:
            self._check_last_query_didnt_burst(cluster, cursor)

    def _run_post_dmls(self, cluster, cursor, tbl, burst):
        self._run_query_check_bursted(cluster, cursor, INSERT_CMD.format(tbl),
                                      burst)
        self._run_query_check_bursted(cluster, cursor,
                                      INSERT_SELECT_CMD.format(tbl, tbl),
                                      burst)
        self._run_query_check_bursted(cluster, cursor, DELETE_CMD.format(tbl),
                                      burst)
        self._run_query_check_bursted(cluster, cursor, UPDATE_CMD.format(tbl),
                                      burst)

    @contextmanager
    def verify_failed_burst_query_status(self, cluster, dml, status):
        try:
            start_time = datetime.datetime.now().replace(microsecond=0)
            start_str = start_time.isoformat(' ')
            yield
        except Exception as e:
            log.info(e)
        finally:
            query = """
                select query from stl_query
                where userid > 1
                and starttime >= '{}'
                and querytxt ilike '%{}%'
                order by starttime asc
                limit 1
                """.format(start_str, dml)
            with self.db.cursor() as cur:
                cur.execute(query)
                qid = cur.fetch_scalar()
                self.verify_query_status(cluster, qid, status)

    # Full dimensions will run about 19 hours, thus skip some cases.
    def _should_skip(self, vector):
        if ((vector.dml in ['insert', 'insert_select'])
            and vector.event == 'EtFakeBurstErrorStepDelete') \
            or (vector.dml == 'delete'
                and vector.event == 'EtFakeBurstErrorStepInsert') \
            or ((vector.dml in ['insert', 'update'])
                and vector.event == 'EtFakeBurstErrorBeforeStreamHeader') \
            or ((vector.dml == ['insert_select', 'delete'])
                and vector.event == 'EtFakeBurstErrorAfterStreamHeader'):
            return True
        else:
            return False

    def base_burst_id_col_cluster_error_in_txn(self, cluster, db_session,
                                               vector, retry):
        burst_table = "bw_id_col_error_" + str(uuid.uuid4().hex[:8])
        burst_session = RedshiftDb(conn_params=get_burst_conn_params())
        schema = db_session.session_ctx.schema
        with db_session.cursor() as dml_cursor, \
                burst_session.cursor() as burst_cursor:
            log.info("Setting up tables")
            self._setup_table(burst_table, dml_cursor, vector)

            log.info("Start backup and wait for burst refresh")
            self._start_and_wait_for_refresh(cluster)

            dml_cursor.execute("set query_group to burst;")
            log.info("run dml")
            dml_cmd = self._generate_dml_cmd(vector, burst_table)
            dml_cursor.execute("set query_group to burst;")
            dml_cursor.execute("begin;")
            dml_cursor.execute(
                INSERT_SELECT_CMD.format(burst_table, burst_table))
            self._check_last_query_bursted(cluster, dml_cursor)

            log.info("set event on burst cluster")
            burst_cursor.execute("xpx 'event set {}'".format(vector.event))

            if retry:
                # For delete, it can retry since it does not reach snap in step
                status = 27 if ('AfterStreamHeader' in vector.event
                                and vector.dml != 'delete'
                                ) or 'AfterSnapIn' in vector.event else 29
                with self.verify_failed_burst_query_status(
                        cluster, dml_cmd, status):
                    dml_cursor.execute(dml_cmd)
            else:
                with self.verify_failed_burst_query_status(
                        cluster, dml_cmd, 25):
                    dml_cursor.execute_failing_query(dml_cmd,
                                                     "Simulate burst error")
            dml_cursor.execute("abort;")
            burst_cursor.execute("xpx 'event unset {}'".format(vector.event))
            self._validate_ownership_state(schema, burst_table,
                                           [('Main', 'Undo')])

            dml_cursor.execute("set query_group to metrics;")
            self._check_all_id_cols_not_duplicated(dml_cursor, burst_table)

            log.info("Validation: Start backup and wait for burst refresh")
            self._start_and_wait_for_refresh(cluster)
            if vector.validate_query_mode == 'burst':
                self._run_post_dmls(cluster, dml_cursor, burst_table, True)
            else:
                self._run_post_dmls(cluster, dml_cursor, burst_table, False)
            self._check_all_id_cols_not_duplicated(dml_cursor, burst_table)
            log.info("drop table")
            dml_cursor.execute("drop table {};".format(burst_table))

    def base_burst_id_col_cluster_error_out_txn(self, cluster, db_session,
                                                vector, retry):
        burst_table = "burst_cluster_error_burst" + str(uuid.uuid4().hex[:8])
        burst_session = RedshiftDb(conn_params=get_burst_conn_params())
        schema = db_session.session_ctx.schema
        with db_session.cursor() as dml_cursor, \
                burst_session.cursor() as burst_cursor:
            log.info("Setting up tables")
            self._setup_table(burst_table, dml_cursor, vector)

            log.info("Start backup and wait for burst refresh")
            self._start_and_wait_for_refresh(cluster)

            if 'AfterSnapIn' in vector.event:
                log.info("set event on main cluster")
                db_session.cursor().execute("set query_group to 'noburst';")
                with self.db.cursor() as bootstrap_cursor:
                    bootstrap_cursor.execute("xpx 'event set {}'".format(
                        vector.event))
            else:
                log.info("set event on burst cluster")
                burst_cursor.execute("xpx 'event set {}'".format(vector.event))

            dml_cursor.execute("set query_group to burst;")
            log.info("run dml")
            dml_cmd = self._generate_dml_cmd(vector, burst_table)
            if retry:
                # For delete, it can retry since it does not reach snap in step
                status = 27 if ('AfterStreamHeader' in vector.event
                                and vector.dml != 'delete'
                                ) or 'AfterSnapIn' in vector.event else 29
                with self.verify_failed_burst_query_status(
                        cluster, dml_cmd, status):
                    dml_cursor.execute(dml_cmd)
            else:
                with self.verify_failed_burst_query_status(
                        cluster, dml_cmd, 25):
                    dml_cursor.execute_failing_query(dml_cmd,
                                                     "Simulate burst error")
            if 'AfterSnapIn' in vector.event:
                log.info("set event on main cluster")
                db_session.cursor().execute("set query_group to 'noburst';")
                with self.db.cursor() as bootstrap_cursor:
                    bootstrap_cursor.execute("xpx 'event unset {}'".format(
                        vector.event))
            else:
                log.info("set event on burst cluster")
                burst_cursor.execute("xpx 'event unset {}'".format(
                    vector.event))
            if retry and ('AfterStreamHeader' not in vector.event
                          or vector.dml == 'delete'
                          ) and 'AfterSnapIn' not in vector.event:
                self._validate_ownership_state(schema, burst_table,
                                               [('Burst', 'Dirty')])
            else:
                self._validate_ownership_state(schema, burst_table,
                                               [('Main', 'Undo')])

            dml_cursor.execute("set query_group to metrics;")
            self._check_all_id_cols_not_duplicated(dml_cursor, burst_table)
            log.info("Validation: Start backup and wait for burst refresh")
            self._start_and_wait_for_refresh(cluster)
            if vector.validate_query_mode == 'burst':
                self._run_post_dmls(cluster, dml_cursor, burst_table, True)
            else:
                self._run_post_dmls(cluster, dml_cursor, burst_table, False)
            self._check_all_id_cols_not_duplicated(dml_cursor, burst_table)
            log.info("drop table")
            dml_cursor.execute("drop table {};".format(burst_table))


@pytest.mark.serial_only
@pytest.mark.localhost_only
@pytest.mark.skip_load_data
@pytest.mark.super_simulated_mode
@pytest.mark.super_simulated_no_stable_rc
@pytest.mark.custom_burst_gucs(
    gucs={
        'slices_per_node': '3',
        'burst_enable_write': 'true',
        'burst_enable_write_id_col': 'true',
        'vacuum_auto_worker_enable': 'false',
        'burst_blk_hdr_stream_threshold': 1
    })
@pytest.mark.usefixtures("disable_all_autoworkers")
@pytest.mark.custom_local_gucs(gucs=burst_write_no_retry_gucs)
class TestBurstIDColClusterErrorInTxnNoRetry(BaseBurstIDColClusterError):
    @classmethod
    def modify_test_dimensions(cls):
        return Dimensions(
            dict(
                diststyle=['diststyle even'],
                sortkey=['sortkey(c0)'],
                validate_query_mode=['burst'],
                dml=['insert', 'insert_select', 'delete', 'update'],
                event=[
                    'EtFakeBurstErrorStepDelete', 'EtFakeBurstErrorStepInsert',
                    'EtFakeBurstErrorBeforeStreamHeader',
                    'EtFakeBurstErrorAfterStreamHeader'
                ]))

    @pytest.mark.usefixtures("super_simulated_mode_method")
    def test_bw_id_col_burst_cluster_error_in_txn_no_retry(
            self, cluster, db_session, vector):
        """
        Test: Fails write query on different position in burst cluster, ensure
              query failure, then run write on main/burst cluster and check
              table content for further validation.
        """
        if self._should_skip(vector):
            pytest.skip("Unsupported dimension")

        assert cluster.get_guc_value(
            'burst_enable_insert_failure_handling') == 'off'

        self.base_burst_id_col_cluster_error_in_txn(cluster, db_session,
                                                    vector, False)
